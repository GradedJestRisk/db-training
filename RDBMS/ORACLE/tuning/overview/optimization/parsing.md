# Parsing

> To always have an efficient execution plan, you want to parse every SQL statement executed by the database engine. 
> But conversely, parsing is inherently a very expensive operation. 
> As a result, it must be minimized, and execution plans should be reused as much as possible — but not too much, though.

> The impact of parsing on overall performance is extremely variable. In some cases, it’s simply not noticeable. In other cases, it’s one of the major causes of performance problems. If you have problems with parsing, it usually means the application doesn’t handle it correctly. 


### how much parsing  (v$sess_time_model) ?

views tells how muc parsing doen (count), not how much time
> The problem is that several dynamic performance views contain counters that detail the number of soft parses, hard parses, and executions. These counters, as well as the ratios based on them, are useless because they provide no information about the time spent parsing. Note that with parses, this is a real problem because they have no typical duration. In fact, depending on the complexity of the SQL statement and the objects it references, the duration of parses commonly differs by several orders of magnitude. Simply put, such counters tell you only whether the database engine has done a few or many parses, without any information about whether this is a problem. Because of this, in practice they may be useful only for trending purposes.


You can get time here in `v$sess_time_model`
```oracle
WITH
  db_time AS (SELECT sid, value
              FROM v$sess_time_model
              WHERE 1=1
              AND sid = 18
              AND stat_name = 'DB time')
SELECT ses.stat_name AS statistic,
       round(ses.value / 1E6, 3) AS seconds,
       round(ses.value / nullif(tot.value, 0) * 1E2, 1) AS "%"
FROM v$sess_time_model ses, db_time tot
WHERE ses.sid = tot.sid
AND ses.stat_name <> 'DB time'
AND ses.value > 0
ORDER BY ses.value DESC;
```

Not much parsing here

| STATISTIC                                    | SECONDS | %     |
|:---------------------------------------------|:--------|:------|
| DB CPU                                       | 10.061  | 100.3 |
| sql execute elapsed time                     | 1.718   | 17.1  |
| parse time elapsed                           | 0.467   | 4.7   |
| hard parse elapsed time                      | 0.035   | 0.4   |
| hard parse \(sharing criteria\) elapsed time | 0.008   | 0.1   |

> Unfortunately, the time model statistics provided by the dynamic performance views just mentioned aren’t helpful in finding out just which SQL statements are causing the problem!

> If you are looking for hard facts and not just clues, there are only two sources of information you can use: 
> -  the output generated by SQL trace
> - -the active session history (v$active_session_history) 

## 2 types of problems

> There are two main kinds of parsing problems. The first is associated with parses lasting a very short time. Let’s call them quick parses. Of course, to be noticeable, a lot of them have to be executed. 

> The second kind of parsing problem is associated with parses lasting a long time. Let’s call this type long parses. This usually happens when the SQL statement is fairly complex and the query optimizer needs a long time to generate an efficient execution plan. In this case, the number of executions isn’t relevant.

## track problems: quick (hard) parse


### tkprof

Generate trace file with tkprof, sorting by 
```shell
tkprof sort=prsela,exeela,fchela
```

Check indirectly the parse time:
- get execution time : 14 seconds
- get count of SQL statements: 10 000 (so many short statements)
- get execution time of longest statement : 99 ms (`0.00` so at maximum  `0.0099` s)  
- no long-running SQL statements, rather a high number of short-running


At enf of file
```text
********************************************************************************
Trace file: DBM11203_ora_8288.trc

     1  session in tracefile.
 10000  user  SQL statements in trace file.
     0  internal SQL statements in trace file.
 10000  SQL statements in trace file.
 10000  unique SQL statements in trace file.
120060  lines in trace file.
    14  elapsed seconds in trace file.
```

top SQL (start of file, because of sort)
```text
call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.00       0.00          0          0          0           0
Execute      1      0.00       0.00          0          0          0           0
Fetch        1      0.00       0.00          0          2          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        3      0.00       0.00 
```

So to check if parsing is involved: yes, it is
- check breakout by type :  95% (5.7/6) of the processing time.
- check hard parse: 10 000  (100%) in `Misses in library cache during parse`)

In `OVERALL TOTALS FOR ALL NON-RECURSIVE STATEMENTS`
```text
call     count       cpu    elapsed
------- ------  -------- ----------
Parse    10000      5.54       5.70
Execute  10000      0.17       0.15
Fetch    10000      0.13       0.14
------- ------  -------- ----------
total    30000      5.86       6.00

Misses in library cache during parse: 10000
```

Check unaccounted time: 
- total is 14 s, executed is 6 s: 8 s missing
- get total wait time : 6 s, still 2 seconds missing

```text
Event waited on                             Times   Max. Wait  Total Waited
----------------------------------------   Waited  ----------  ------------
SQL*Net message to client                   10000        0.00          0.02
SQL*Net message from client                 10000        0.02          6.24
latch: shared pool                              5        0.00          0.00
log file sync                                   1        0.00          0.00
```


Then check SQL (under `SQL ID` section)
- is statement similar, or completely different ?
- if yes, is there any binding variable ?

```text
SELECT pad FROM t WHERE val = 0
SELECT pad FROM t WHERE val = 7218
```

To make it easier, you can extract only SQL statement
```shell
tkprof $TRACE $REPORT sys=no sort=prsela,exeela,fchela record=$SQL_STATEMENT_FILE
grep "SELECT pad FROM t WHERE val =" $SQL_STATEMENT_FILE | wc -l
```
You get 10 000: all statements are same.

### tvd$xtat

No sort options
```shell
tvdxtat –i $TRACE --output $REPORT
```

Same as tkprof, but quicker, as at start of file :
- wait time : 6 s
- execution time (CPU): 6 s
- unaccounted: 2 s

```text
                               Total         Number of Duration per
Component                   Duration       %    Events        Event
--------------------------- -------- ------- --------- ------------
SQL*Net message from client    6.243  43.075    10,000        0.001
CPU                            5.862  40.444       n/a          n/a
unaccounted-for                2.364  16.309       n/a          n/a
SQL*Net message to client      0.024   0.168    10,000        0.000
latch: shared pool             0.000   0.002         5        0.000
log file sync                  0.000   0.002         1        0.000
--------------------------- -------- -------
Total                         14.494 100.000
```

As tvd$xtat recognize statements, only one statement appears : id #1

```text
Statement           Total          Number of Duration per
ID        Type   Duration       % Executions    Execution
--------- ------ -------- ------- ---------- ------------
#1        SELECT   12.130  83.689     10,000        0.001
#2        COMMIT    0.000   0.002          1        0.000
--------- ------ -------- -------
Total              12.130  83.691
```

If you scroll to #1:
- all the time is spent parsing rather than processing
- and all were hard (all misses) 

```text
******************************************* STATEMENT 1 ********************************************

Call     Count Misses   CPU Elapsed PIO    LIO Consistent Current  Rows
------- ------ ------ ----- ------- --- ------ ---------- ------- -----
Parse   10,000 10,000 5.548   5.705   0      0          0       0     0
Execute 10,000      0 0.176   0.156   0      0          0       0     0
Fetch   10,000      0 0.138   0.148   0 23,051     23,051       0 3,048
------- ------ ------ ----- ------- --- ------ ---------- ------- -----
Total   30,000 10,000 5.862   6.009   0 23,051     23,051       0 3,048
```

### ash

As short parsing has few chance to be sampled by ash, do not hope too much.

> The analysis performed via active session history isn’t very useful in this case. This is expected because sampling a single session over a dozen seconds can result in only a few samples.

Check session with much parse

Get parse time (`in_parse` and `in_hard_parse`) for a session
```oracle
SELECT count(*) AS db_time,
       count(nullif(in_parse, 'N')) AS parse_time,
       count(nullif(in_hard_parse, 'N')) AS hard_parse_time
FROM v$active_session_history
WHERE session_id = 68
AND session_serial# = 23;
```

```text
DB_TIME PARSE_TIME HARD_PARSE_TIME
------- ---------- ---------------
      5          4               4
```

If there is a problem, identify the query in the session
```oracle
SELECT sql_id,
       count(*) AS db_time,
       count(nullif(in_parse, 'N')) AS parse_time,
       count(nullif(in_hard_parse, 'N')) AS hard_parse_time
FROM v$active_session_history
WHERE 1=1
--     AND session_id = 68
--     AND session_serial# = 23
    
GROUP BY sql_id
```

| SQL_ID        | DB_TIME | PARSE_TIME | HARD_PARSE_TIME |
|:--------------|:--------|:-----------|:----------------|
| 6xvzxzck50czk | 1       | 1          | 1               |
| 1h50ks4ncswfn | 1       | 0          | 0               |


```oracle
SELECT 
    ash.session_id,
    ash.sql_id,
    ash.*
FROM v$active_session_history ash
WHERE 1=1
    AND sql_id = '6xvzxzck50czk'
```

Then identify its text:
- you can use  `v$sqlarea`
- but retention time is greater for `v$sqlstats`

```oracle
SELECT sql_text
FROM v$sqlstats
WHERE sql_id = '6xvzxzck50czk'
```

```oracle
SELECT 
    a.sql_id, s.sql_text, 
    count(*) AS parse_time
FROM v$active_session_history a, v$sqlstats s
WHERE 1=1
    AND a.sql_id = s.sql_id(+)
--     AND a.session_id = 68
--     AND a.session_serial# = 23
    AND a.in_parse = 'Y'
GROUP BY a.sql_id, s.sql_text
ORDER BY count(*) DESC;
```

## track problems: long (hard) parse

> Active session history isn’t covered. The reason is quite simple: it’s rare to see parse calls that take more than few seconds. As a result, most of the time it isn’t sensible to analyze such a problem through active session history. 

### tkprof

What happened ?
 - 3 statements in 2 seconds
 - 1 statement taking all execution time
 - this statement is all parse 

End of file
```text
   1  session in tracefile.
   3  user  SQL statements in trace file.
  13  internal SQL statements in trace file.
  16  SQL statements in trace file.
  16  unique SQL statements in trace file.
9644  lines in trace file.
   2  elapsed seconds in trace file.
```

Start of file: statement
```text
call     count       cpu    elapsed
------- ------  -------- ----------
Parse        1      2.65       2.65
Execute      1      0.00       0.00
Fetch        2      0.00       0.00
------- ------  -------- ----------
total        4      2.65       2.66
```

### tvd$xtat

All CPU
```text
                               Total         Number of Duration per
Component                   Duration       %    Events        Event
--------------------------- -------- ------- --------- ------------
CPU                            2.769  98.383       n/a          n/a
db file sequential read        0.027   0.943       314        0.000
unaccounted-for                0.017   0.596       n/a          n/a
SQL*Net message from client    0.002   0.078         3        0.001
SQL*Net message to client      0.000   0.000         3        0.000
--------------------------- -------- -------
Total                          2.814 100.000
```

99 % for statement #1 
```text
Statement           Total          Number of Duration per
ID        Type   Duration       % Executions    Execution
--------- ------ -------- ------- ---------- ------------
#1        SELECT    2.791  99.167          1        2.791
#9        PL/SQL    0.005   0.166          1        0.005
#12       PL/SQL    0.002   0.071          1        0.002
--------- ------ -------- -------
Total               2.797  99.404
```

Statement #1 : all parse, 1 parse, 1 hard (count=misses=1)
```text
Call    Count Misses   CPU Elapsed
------- ----- ------ ----- -------
Parse       1      1 2.653   2.654
Execute     1      0 0.002   0.002
Fetch       2      0 0.004   0.006
------- ----- ------ ----- -------
Total       4      1 2.659   2.661
```

## solving quick parse

> The first thing to do when a SQL statement causing parsing problems uses literals that are constantly changing is to replace the literals with bind variables. For that, you have to use a prepared statement. The aim of using a prepared statement is to share a single cursor for all SQL statements and, consequently, to avoid unnecessary hard parses by turning them into soft parses.

Target is, for all similar operations for a client:
 - single hard parse
 - single soft parse

There wil however be limitations:
- resource usage in memory, keep track of opened cursors
- optimize should generate sound execution plan (skewing, histogram, plan invalidation..)

### remove hard parse

Prepared statement 
- use same plan for all statement
- change bind value for each statement

Using prepared statement : eliminate all but one hard parse

Workflow is:
- create prepared statement
- set bind variable
- execute statement / fetch data
- close statement
- loop to next bind value => create a prepared statement..

But it will cause an overhead for the client, so go all teh way and reuse your prepared statement as following.

### remove soft parse in code

Reusing Prepared Statements : eliminate all but one soft parse.

To do so, the client should not close the prepared statement
> performance problems created by applications that cause too many soft parses because cursors are unnecessarily opened and closed.

Workflow is:
- create prepared statement
- set bind variable
- execute statement / fetch data
- loop to next bind value
- close statement (cursor)

You get additional improvement by sending to database only the bind value, not the whole statement. 

>  substantial reduction of the size of the messages both received and sent from the database engine, caused by the data sent over the network in order to open and close a new cursor (sent only once over the network, together with the first open, and the cursor is closed only once, at the end).

> the response time is expected to depend on the network speed. If the network is fast, the impact of the communication between the client and the server is low or not even noticeable. If the network is slow, the impact may be significant.

No metric on statement level, only on session level
```oracle
SELECT ss.sid, sn.name, ss.value
FROM v$statname sn, v$sesstat ss
WHERE 1=1
    AND sn.statistic# = ss.statistic#
    AND sn.name LIKE 'bytes%client'
--     AND ss.sid = 42
ORDER BY ss.value DESC
```

### remove soft parse using client cache

Called Client-Side Statement Caching

> Whenever the application closes a cursor, instead of really closing it, the client-side database layer (which is responsible for communicating with the database engine) keeps it open and adds it to a cache. 
> Then, later, if a cursor based on the same SQL statement is opened and parsed again, instead of really opening and parsing it, the cached cursor is reused. 
> Thus, the soft parse shouldn’t take place. 

> To take advantage of this feature, it’s usually only a matter of enabling it and defining the maximum number of cursors that can be cached by a session. Note that when the cache is full, the least recently used cursors are closed and replaced by newer ones. In any case, it makes no sense to exceed the value of the open_cursors initialization parameter.

### remove soft parse using cursor sharing

> If an application executes SQL statements containing literals and if cursor sharing is enabled, the database engine automatically replaces the literals with bind variables.
> => Hard parses might be turned into soft parses

In PL/SQL, it does NOT work for:
- static SQL statements;
- dynamic SQL statements, if literals are mixed with bind variables.

Parameter `cursor_sharing`:
- disabled: `exact`
- enabled: `force`

```oracle
SELECT value
FROM v$parameter WHERE name = 'cursor_sharing';
```

See also "adaptive cursor sharing"

> The problem related to the value force is that a single child cursor can be used for all SQL statements sharing the same text after the replacement of the literals. 
> Consequently, the literals (that, among other things, are essential for taking advantage of histograms) are peeked only during the generation of the execution plan related to the **first** submitted SQL statement. 
> Naturally, this could lead to suboptimal execution plans because literals used in subsequent SQL statements might require different execution plans.


Whith `simialr`

> Before reusing a cursor that is already available, the SQL engine checks whether a histogram exists for one of the replaced literals. If it doesn’t exist, any available child cursor that has a compatible execution environment can be used. If it does exist, only a child cursor that has been created with the very same literal value can be used. As a result, with similar, instead of having a single parent cursor for every literal value, you end up having a single child cursor for every literal value (which uses less memory).
> But the parse time increases linearly because, during the parse, the SQL engine has to check whether an already available child cursor can be reused. Therefore, the list of child cursors must be scanned and every child cursor probed for compatibility.

> So the behavior depends on the existence of relevant histograms:
> - if they do exist, similar behaves like exact. 
> - if they don’t exist, similar behaves like force. 
> This means that if you are facing parsing problems, more often than not, it’s pointless to use similar.

### remove soft parse using server-side cache

Use if you can't change client (code or cache)
>A cursor is put in the cursor cache only when it has been executed several times

> This feature is similar to client-side statement caching because it’s designed to reduce overhead when too many soft parses are taking place. From a conceptual point of view, the two types of statement caching are similar, except that one is implemented on the server side and the other on the client side. 
> From a performance point of view, however, the differences are considerable. In fact, the server-side implementation is far less powerful than the client-side implementation.
> This is because the server-side implementation reduces the overhead of soft parses on the server side only, and in more than a few circumstances, the overhead of soft parses is much greater on the client than on the server. 
> The only real advantage of the server-side implementation is the ability to cache SQL statements that are executed by PL/SQL or Java code deployed in the database engine.

```oracle
SELECT value
FROM v$parameter WHERE name = 'session_cached_cursors';
```
50


Check cache usage (invalid for PL/SQL)
```oracle
SELECT ss.sid, sn.name, ss.value
FROM v$statname sn, v$sesstat ss
WHERE 1=1
    AND sn.statistic# = ss.statistic#
    AND sn.name IN ('session cursor cache hits',
                    'session cursor cache count',
                    'parse count (total)')
    AND ss.sid = 41
;
```
```text
NAME                            VALUE
-------------------------- ----------
session cursor cache hits        9997
session cursor cache count          9
parse count (total)             10008
```

Heuristic:
- is `session cursor cache hits` < `parse count (total)` ? = is cache working bad ?
  - yes: is `session cursor cache count` = `session_cached_cursors` ? = have they all been allocated ?
        - yes : is `session_cached_cursors` << `open_cursors` ? = is there room for more cursors ?
          - yes: increase `session_cached_cursors`


## solving long parse

> In case of long parses that are executed only a few times (or as in the previous example, only once), it’s usually not possible to avoid the parse phase. 
> In fact, the SQL statement must be parsed at least once. 
> In addition, if the SQL statement is rarely executed, a hard parse is probably inevitable because the cursor will be aged out of the library cache between executions. This is especially true if no bind variables are used.

> Therefore, the only possible solution is to reduce the parsing time itself.

> What causes long parse times? 
> - the query optimizer evaluating too many different execution plans
> - recursive queries executed on behalf of dynamic sampling

Solving recursive 
- reduce the level of dynamic sampling
- completely deactivate it

Solving high number execution plan: forcing a specific execution plan
- in code : hints
- in database: stored outlines